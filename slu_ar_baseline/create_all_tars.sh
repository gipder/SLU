#!/bin/bash
# create_all_tars.sh - TAR íŒŒì¼ í•œë²ˆì— ìƒì„± (ìºì‹œ í¬í•¨)

set -e

EXTRACT_FEAT_DIR="../data/slu/hubert_deberta_cache"
TAR_OUTPUT_DIR="../data/slu/hubert_deberta_cache_tar"
TOKENIZER="facebook/hubert-large-ls960-ft"

echo "ğŸš€ TAR ìƒì„± ì‹œì‘ (ë©”íƒ€ë°ì´í„° ìºì‹œ ìë™ ìƒì„±)"
echo "==========================================="

# Train ë°ì´í„°
echo ""
echo "ğŸ“¦ Train ë°ì´í„° ì²˜ë¦¬..."
python create_tar_dataset.py \
  --source_dir $EXTRACT_FEAT_DIR \
  --output_dir $TAR_OUTPUT_DIR \
  --task train \
  --num_shards 256 \
  --tokenizer_model_name $TOKENIZER

# Eval ë°ì´í„°ë“¤
for eval_task in eval_0 eval_1; do
  if [ -d "$EXTRACT_FEAT_DIR/${eval_task}"* ]; then
    echo ""
    echo "ğŸ“¦ $eval_task ë°ì´í„° ì²˜ë¦¬..."
    python create_tar_dataset.py \
      --source_dir $EXTRACT_FEAT_DIR \
      --output_dir $TAR_OUTPUT_DIR \
      --task $eval_task \
      --num_shards 32 \
      --tokenizer_model_name $TOKENIZER
  fi
done

# Test ë°ì´í„°ë“¤
for test_task in test_0 test_1; do
  if [ -d "$EXTRACT_FEAT_DIR/${test_task}"* ]; then
    echo ""
    echo "ğŸ“¦ $test_task ë°ì´í„° ì²˜ë¦¬..."
    python create_tar_dataset.py \
      --source_dir $EXTRACT_FEAT_DIR \
      --output_dir $TAR_OUTPUT_DIR \
      --task $test_task \
      --num_shards 64 \
      --tokenizer_model_name $TOKENIZER
  fi
done

echo ""
echo "==========================================="
echo "âœ… ëª¨ë“  TAR íŒŒì¼ ë° ìºì‹œ ìƒì„± ì™„ë£Œ!"
echo ""
echo "ìƒì„±ëœ íŒŒì¼:"
ls -lh $TAR_OUTPUT_DIR/*.tar $TAR_OUTPUT_DIR/.metadata_cache_*.pkl 2>/dev/null | tail -20
